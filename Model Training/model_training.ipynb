{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "models = tf.keras.models\n",
    "applications = tf.keras.applications\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "MAX_SEQ_LENGTH = 25\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_names</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31080872_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f08696669_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06118078_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f98560186_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18938233_v.mp4</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30959717_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f83411458_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95768401_v.mp4</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13846948_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f53451125_nv.mp4</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_names labels\n",
       "0   31080872_nv.mp4     nv\n",
       "1  f08696669_nv.mp4     nv\n",
       "2   06118078_nv.mp4     nv\n",
       "3  f98560186_nv.mp4     nv\n",
       "4    18938233_v.mp4      v\n",
       "5   30959717_nv.mp4     nv\n",
       "6  f83411458_nv.mp4     nv\n",
       "7    95768401_v.mp4      v\n",
       "8   13846948_nv.mp4     nv\n",
       "9  f53451125_nv.mp4     nv"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = '/Users/saif/Desktop/vm_server/fyp_data'\n",
    "files = os.listdir(folder_path)\n",
    "video_files = []\n",
    "for f in files:\n",
    "    if '.mp4' in f:\n",
    "        video_files.append(f)\n",
    "dataset = {'video_names': video_files, 'labels':[]}\n",
    "for v in video_files:\n",
    "    if '_nv' in v:\n",
    "        dataset['labels'].append('nv')\n",
    "    elif '_v' in v:\n",
    "        dataset['labels'].append('v')\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 3037\n",
      "Total videos for testing: 338\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.1, random_state=42)\n",
    "print(f\"Total videos for training: {len(train)}\")\n",
    "print(f\"Total videos for testing: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "v     1594\n",
      "nv    1443\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = train['labels'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = applications.ResNet50V2(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = applications.resnet_v2.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nv', 'v']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train[\"labels\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed = 99.7%%"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    count = 0\n",
    "    video_paths = df[\"video_names\"].values.tolist()\n",
    "    labels = df[\"labels\"].values\n",
    "    labels = np.array(label_processor(labels[..., None]))\n",
    "\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            frame_indices = np.arange(0, video_length, (video_length // MAX_SEQ_LENGTH)+1)\n",
    "\n",
    "            for j, frame_index in enumerate(frame_indices):\n",
    "                if frame_index < video_length:\n",
    "                    temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                        batch[None, int(frame_index), :], verbose=0,\n",
    "                    )\n",
    "                else:\n",
    "                    break\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        val = round((count/num_samples)*100, 2)\n",
    "        print(f'\\rcompleted = {val}%', end='', flush=True)\n",
    "        count += 1\n",
    "\n",
    "    return frame_features, labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train, folder_path)\n",
    "test_data, test_labels = prepare_all_videos(test, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    # Define the input layer.\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "\n",
    "    # First GRU layer with increased number of units and return sequences.\n",
    "    x = keras.layers.GRU(128, return_sequences=True)(frame_features_input)\n",
    "    x = keras.layers.BatchNormalization()(x)  # Add batch normalization for stable training\n",
    "\n",
    "    # Second GRU layer with a smaller number of units.\n",
    "    x = keras.layers.GRU(128, return_sequences=True)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Third GRU layer with even fewer units.\n",
    "    x = keras.layers.GRU(64)(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)  # Increase dropout rate to avoid overfitting\n",
    "\n",
    "    # Add a dense layer with ReLU activation and batch normalization.\n",
    "    x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Add the output layer with softmax activation.\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    rnn_model = keras.Model(frame_features_input, output)\n",
    "\n",
    "    # Compile the model with appropriate loss, optimizer, and metrics.\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    filepath = \"kpt2.weights.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_deep_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        validation_split=0.2,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=32,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    test_loss, accuracy = seq_model.evaluate(test_data, test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    # Predict on test data\n",
    "    predictions = seq_model.predict(test_data)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_labels.flatten()\n",
    "\n",
    "    # Print the distribution of true and predicted labels\n",
    "    print(\"True labels distribution:\", Counter(true_classes))\n",
    "    print(\"Predicted labels distribution:\", Counter(predicted_classes))\n",
    "\n",
    "    # Calculate and print F1 score, precision, and recall using sklearn\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_names, digits=2, zero_division=0)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Calculate and display the confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "    # Save the entire model as an .h5 file\n",
    "    model_save_path = \"final_model.h5\"\n",
    "    seq_model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "class_names = [\"nv\", \"v\"]  # Replace with actual class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.7118\n",
      "Epoch 1: val_loss improved from inf to 0.57594, saving model to kpt2.weights.h5\n",
      "76/76 [==============================] - 6s 35ms/step - loss: 0.5808 - accuracy: 0.7118 - val_loss: 0.5759 - val_accuracy: 0.6957\n",
      "Epoch 2/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8460\n",
      "Epoch 2: val_loss improved from 0.57594 to 0.46725, saving model to kpt2.weights.h5\n",
      "76/76 [==============================] - 2s 23ms/step - loss: 0.3596 - accuracy: 0.8460 - val_loss: 0.4672 - val_accuracy: 0.7829\n",
      "Epoch 3/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.9012\n",
      "Epoch 3: val_loss did not improve from 0.46725\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.2495 - accuracy: 0.9012 - val_loss: 0.8594 - val_accuracy: 0.7155\n",
      "Epoch 4/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9333\n",
      "Epoch 4: val_loss improved from 0.46725 to 0.42944, saving model to kpt2.weights.h5\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.1821 - accuracy: 0.9333 - val_loss: 0.4294 - val_accuracy: 0.8289\n",
      "Epoch 5/20\n",
      "75/76 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9488\n",
      "Epoch 5: val_loss improved from 0.42944 to 0.35268, saving model to kpt2.weights.h5\n",
      "76/76 [==============================] - 2s 23ms/step - loss: 0.1411 - accuracy: 0.9485 - val_loss: 0.3527 - val_accuracy: 0.8882\n",
      "Epoch 6/20\n",
      "75/76 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9642\n",
      "Epoch 6: val_loss did not improve from 0.35268\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.1056 - accuracy: 0.9642 - val_loss: 0.3610 - val_accuracy: 0.8849\n",
      "Epoch 7/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9687\n",
      "Epoch 7: val_loss did not improve from 0.35268\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0892 - accuracy: 0.9687 - val_loss: 0.4970 - val_accuracy: 0.8470\n",
      "Epoch 8/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9547\n",
      "Epoch 8: val_loss did not improve from 0.35268\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.1297 - accuracy: 0.9547 - val_loss: 0.3615 - val_accuracy: 0.8684\n",
      "Epoch 9/20\n",
      "75/76 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9646\n",
      "Epoch 9: val_loss improved from 0.35268 to 0.33639, saving model to kpt2.weights.h5\n",
      "76/76 [==============================] - 2s 23ms/step - loss: 0.1026 - accuracy: 0.9646 - val_loss: 0.3364 - val_accuracy: 0.8914\n",
      "Epoch 10/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9765\n",
      "Epoch 10: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0684 - accuracy: 0.9765 - val_loss: 0.4637 - val_accuracy: 0.8651\n",
      "Epoch 11/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9708\n",
      "Epoch 11: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0879 - accuracy: 0.9708 - val_loss: 0.8597 - val_accuracy: 0.7730\n",
      "Epoch 12/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9683\n",
      "Epoch 12: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0913 - accuracy: 0.9683 - val_loss: 0.6137 - val_accuracy: 0.8405\n",
      "Epoch 13/20\n",
      "75/76 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9758\n",
      "Epoch 13: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0747 - accuracy: 0.9757 - val_loss: 0.4157 - val_accuracy: 0.8832\n",
      "Epoch 14/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9761\n",
      "Epoch 14: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0798 - accuracy: 0.9761 - val_loss: 0.4159 - val_accuracy: 0.8799\n",
      "Epoch 15/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9918\n",
      "Epoch 15: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0366 - accuracy: 0.9918 - val_loss: 0.4690 - val_accuracy: 0.8914\n",
      "Epoch 16/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9741\n",
      "Epoch 16: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 21ms/step - loss: 0.0804 - accuracy: 0.9741 - val_loss: 0.4309 - val_accuracy: 0.8717\n",
      "Epoch 17/20\n",
      "75/76 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9696\n",
      "Epoch 17: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0820 - accuracy: 0.9699 - val_loss: 0.4375 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9778\n",
      "Epoch 18: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 21ms/step - loss: 0.0611 - accuracy: 0.9778 - val_loss: 0.4294 - val_accuracy: 0.8816\n",
      "Epoch 19/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9909\n",
      "Epoch 19: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0341 - accuracy: 0.9909 - val_loss: 0.5131 - val_accuracy: 0.8783\n",
      "Epoch 20/20\n",
      "76/76 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9881\n",
      "Epoch 20: val_loss did not improve from 0.33639\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0473 - accuracy: 0.9881 - val_loss: 0.4677 - val_accuracy: 0.8882\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 0.3372 - accuracy: 0.9083\n",
      "Test accuracy: 90.83%\n",
      "11/11 [==============================] - 1s 12ms/step\n",
      "True labels distribution: Counter({1: 177, 0: 161})\n",
      "Predicted labels distribution: Counter({0: 178, 1: 160})\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          nv       0.87      0.96      0.91       161\n",
      "           v       0.96      0.86      0.91       177\n",
      "\n",
      "    accuracy                           0.91       338\n",
      "   macro avg       0.91      0.91      0.91       338\n",
      "weighted avg       0.91      0.91      0.91       338\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to final_model.h5\n"
     ]
    }
   ],
   "source": [
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
